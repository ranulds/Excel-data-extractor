{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import base64\n",
    "import json\n",
    "import csv\n",
    "import shutil\n",
    "from typing import List\n",
    "from natsort import os_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "GPT4V_ENDPOINT = \"YOUR_API_ENDPOINT\"\n",
    "GPT4V_KEY = \"YOUR_API_KEY\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": GPT4V_KEY,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_evaluate_content(image_path:str, extract_list:List[str]):\n",
    "    encoded_image = base64.b64encode(open(image_path, 'rb').read()).decode('ascii')\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    You are an AI assistant that helps extract text from images of spreadsheets.\n",
    "    You will be given the list of columns to extract text from.\n",
    "    You should extract text from each column of the spreadsheet.\n",
    "    Reply only with a JSON object.\n",
    "    The JSON object should be an array of objects where each object represents a row in the spreadsheet.\n",
    "    The keys of the JSON must be the column number.\n",
    "    Within strings, you must replace all double-quotes with single quotes.\n",
    "\n",
    "    For example:\n",
    "    [\n",
    "        {\n",
    "            \"1\": \"ESRS2.94GOV-18\",\n",
    "            \"2\": \"GOV-1\",\n",
    "            \"3\": \"21 (e)\",\n",
    "            \"4\": \"N\",\n",
    "            \"5\": \"%\",\n",
    "            \"6\": \"-\"\n",
    "        }\n",
    "    ]\n",
    "    \"\"\"\n",
    "    user_prompt = \"\"\"\n",
    "    extract the following columns from the image.\n",
    "    columns: {0}\n",
    "    \"\"\".format(extract_list)\n",
    "\n",
    "    payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [\n",
    "            {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": system_prompt\n",
    "            }\n",
    "        ]\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{encoded_image}\",\n",
    "                \"detail\": \"high\"\n",
    "            }\n",
    "            },\n",
    "            {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": user_prompt\n",
    "            }\n",
    "        ]\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_p\": 0.0,\n",
    "    \"max_tokens\": 4096\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(GPT4V_ENDPOINT, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
    "    response_json = response.json()\n",
    "    print(f\"Tokens: {response_json['usage']}\")\n",
    "    result=response_json['choices'][0]['message']['content']\n",
    "    try:\n",
    "        # if the result contains json then remove it\n",
    "        result=result.replace(\"json\",\"\")\n",
    "        result=result.replace(\"```\",\"\")\n",
    "        result=result.replace(\"\\n\",\"\")\n",
    "        result=result.replace(\"\\\\\",\"\")\n",
    "        result=json.loads(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extract_evaluate_content: {e}\")\n",
    "        result=result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_keys_in_list(dicts, key_mapping):\n",
    "    for d in dicts:\n",
    "        for old_key, new_key in key_mapping.items():\n",
    "            if old_key in d:\n",
    "                d[new_key] = d.pop(old_key)\n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_mapping = {\n",
    "    \"1\": \"Unique Element ID 17/05\",\n",
    "    \"2\": \"Description\"\n",
    "}\n",
    "\n",
    "# key_mapping = {\n",
    "#     \"1\": \"Unique Element ID 17/05\",\n",
    "#     \"2\": \"Data Element Unit\",\n",
    "#     \"3\": \"Defined Terms\",\n",
    "#     \"4\": \"Interpretation/ external references\"\n",
    "# }\n",
    "\n",
    "# key_mapping = {\n",
    "#     \"1\": \"Unique Element ID 17/05\",\n",
    "#     \"2\": \"Datapoint\",\n",
    "#     \"3\": \"Mandatory calc methodology\",\n",
    "#     \"4\": \"Calculation methodology\",\n",
    "#     \"5\": \"Unit (Quantitative only)\",\n",
    "#     \"6\": \"Datapoint Description\",\n",
    "#     \"7\": \"Data Element Unit\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "\n",
    "os.makedirs('merged', exist_ok=True)\n",
    "\n",
    "files = os.listdir()\n",
    "\n",
    "files = os_sorted(files)\n",
    "\n",
    "for filename_ext in files:\n",
    "    try:\n",
    "        if filename_ext.endswith(('.png')):\n",
    "            filename = filename_ext.split(\".\")[0]\n",
    "            print(filename)\n",
    "\n",
    "            input_string = extract_evaluate_content(filename_ext, [\"Unique Element ID 17/05\",\"Description\"])\n",
    "            # input_string = extract_evaluate_content(filename_ext, [\"Unique Element ID 17/05\",\"Data Element Unit\",\"Defined Terms\", \"Interpretation/ external references\"])\n",
    "            # input_string = extract_evaluate_content(filename_ext, [\"Unique Element ID 17/05\",\"Datapoint\",\"Mandatory calc methodology\", \"Calculation methodology\",\"Unit (Quantitative only)\",\"Datapoint Description\",\"Data Element Unit\"])\n",
    "            print(input_string)\n",
    "\n",
    "            replace_json_data = replace_keys_in_list(input_string, key_mapping)\n",
    "\n",
    "            all_data.append(replace_json_data)\n",
    "            shutil.move(filename_ext, f'merged/{filename_ext}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        break\n",
    "\n",
    "keys = all_data[0][0].keys()\n",
    "\n",
    "filename_csv = 'merged.csv'\n",
    "with open(filename_csv, 'w', newline='') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "    dict_writer.writeheader()\n",
    "    for data in all_data:\n",
    "        dict_writer.writerows(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
